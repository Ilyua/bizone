{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import decomposition\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,recall_score,make_scorer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# стороняя библиотека для работы с несбалансированными датасетами\n",
    "# pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# настройки отображения графиков\n",
    "# %config InlineBackend.figure_format = 'svg' \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "%matplotlib inline\n",
    "\n",
    "# увеличим  размер графиков\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8,7\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# для воспроизводимости\n",
    "r_state = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что все считалось должным образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сперва посмотрим на распределение меток у целевого класса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot(df['Class']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим, насколько мошеннические транзакции коррелируют со временем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df[df['Class']==1]['Time'],100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, распределение числа мошеннических транзакций во времени имеет примерно равномерный характер, следовательно, можно исключить из выборки этот признак. Тем более, что это время отсчитывалось, начиная от первой транзакции, следовательно, оно не имеет ценности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как пространство признаков изображается при двумерной проекции(на примере признаков 'V11', 'V12', 'V13', 'V14', 'V15') :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rcParams['figure.figsize'] = 12,12\n",
    "# sns_plot = sns.pairplot(df,vars=['V11', 'V12', 'V13', 'V14', 'V15'],hue=\"Class\",markers=[\"o\", \"s\"])\n",
    "# rcParams['figure.figsize'] = 8,7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения качественных оценок работы алгоритма, я буду сравнивать такие метрики как:\n",
    "- **Recall score**\n",
    "\n",
    "   Это оценка вида: \n",
    "   \n",
    "   $$score = {tp \\over tp + fn}$$\n",
    "   \n",
    "   tp - число предсказаний, когда модель верно обнаружила нужные транзакции.\n",
    "   \n",
    "   fn - число предсказаний, когда модель не распознала поддельный перевод.\n",
    "   \n",
    "   Чем ближе это значение к 1, тем меньше модель пропускает поддельных транзакций. Но, возможно, она будет помечать некоторые переводы как поддельные, хотя они таковыми не являются. Следующие метрики должны помочь проконтролировать этот аспект.\n",
    "   \n",
    "   \n",
    "- **Accuracy**\n",
    "\n",
    "   Доля верных ответов, будем его тоже учитывать.\n",
    "   \n",
    "   \n",
    "- **ROC AUC score**\n",
    "\n",
    "   Площадь, ограниченная ROC-кривой и осью доли ложных положительных классификаций.\n",
    "   Эта метрика позволяет судить о качестве бинарной классификации и в совокупности с Recall score должна дать нам наглядное представление о работе классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=10000,random_state = r_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью этой функции будем выводить информацию обо всех метриках для данной выборки и классификатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_metrics_validation(clf,X,Y_true):\n",
    "    print(\"Accuracy score: \"+ str(accuracy_score(Y_true,clf.predict(X))))\n",
    "    print(\"ROC AUC score: \"+ str(roc_auc_score(Y_true,clf.predict_proba(X)[:,1]))) # нас интересуют положительные результаты\n",
    "    print(\"Recall score: \"+ str(recall_score(Y_true,clf.predict(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, что получить сбалансированный датасет, я буду использовать алгоритм ADASYN(Adaptive Synthetic Sampling),поскольку SMOTE (Synthetic Minority Over-sampling Technique) создает больше примеров внутри кластера, а ADASYN создает больше синтетических примеров на границе. \n",
    "\n",
    "В случае, когда данные генерируются ADASYN, модель становится более \"подозрительной\", поскольку будет лучше опознавать мошеннические транзакции на границе двух кластеров, ведь ADASYN может расширить границы имеющего кластера. Хотя это и может привести к ошибкам рода False Positive, мне кажется, что такой подход будет надежнее и более подходит для предотвращения мошенничества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производить оценку метрик я буду на трех датасетах.\n",
    "\n",
    "1. На исходном\n",
    "2. На тестовой части датасета, сгенерированного с помощью алгоритма ADASYN. \n",
    "3. На датасете, полученным контатенацией равных долей поддельных транзакций и неподдельных. То есть, я соединил все поддельные транзакции с тем же числом неподдельных (функция ниже)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединим строки поддельных с переводов исходного датасета с таким же количеством неподдельных\n",
    "def create_balanced_data_from_initial(data):\n",
    "    fraud = data[(data['Class']==1)]\n",
    "    not_fraud = df.sample(data[(data['Class']==0)],n=len(fraud),random_state = r_state)\n",
    "    new_df=pd.concat([fraud,not_fraud])      \n",
    "    X = new_df.drop(['Class','Time'], axis=1)\n",
    "    Y = new_df['Class']\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение алгоритма ADASYN\n",
    "def create_balanced_data_adasyn(x,y):\n",
    "    sm = ADASYN(random_state=12, ratio = 'minority')\n",
    "    X,Y = sm.fit_sample(x, y)\n",
    "    X = pd.DataFrame(X,columns = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'] )\n",
    "    Y = pd.DataFrame(Y,columns = ['Class'])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка модели на указанных датасетах\n",
    "def estimate_model(clf, X_balanced, y_balanced, X_original,y_original, X_test, y_test):\n",
    "    print('\\nМетрики на оригинальном датасете: \\n')\n",
    "    all_metrics_validation(clf,X_original,y_original)\n",
    "    print('\\nМетрики на тестовой части :\\n')\n",
    "    all_metrics_validation(clf,X_test, y_test)\n",
    "    print('\\nМетрики на небольшой сбалансированой части из оригинального датасета:\\n')\n",
    "    all_metrics_validation(clf,X_balanced, y_balanced)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем данные на матрицу Х и вектор ответов Y\n",
    "X_original = df.drop(['Class','Time'], axis=1)\n",
    "y_original = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим на тестовую и тренировочную\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original, y_original, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сбалансированный датасет из исходного\n",
    "X_balanced, y_balanced = create_balanced_data_from_initial(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, при генерации данных ADASYN, необходимо сначала отделить тестовую и проверочную выборки, а затем для каждой сгенерировать новые данные. Тк в противном случае, если сначала создать новых данных, а потом разделить выборку, то синтетические данные попадут в проверочный сет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_adasyn, y_train_adasyn = create_balanced_data_adasyn(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_adasyn, y_test_adasyn = create_balanced_data_adasyn(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y_train_adasyn['Class']);y_train_adasyn['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {'max_features': ['auto'], 'min_samples_leaf': range(15,20,2),'max_depth': range(3,7,1),'n_estimators':range(10,50,10),'n_jobs':[-1]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=r_state)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "gcv = GridSearchCV(rfc, parameters, n_jobs=-1, cv=skf, verbose=1,scoring='recall')\n",
    "\n",
    "gcv.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gcv.best_estimator_\n",
    "gcv.best_params_ , gcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_model(clf, X_balanced, y_balanced, X_original,y_original, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {'n_neighbors': range(10,30,5),'n_jobs':[-1]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=r_state)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "gcv = GridSearchCV(knn, parameters, n_jobs=-1, cv=skf, verbose=1,scoring='recall')\n",
    "\n",
    "gcv.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gcv.best_estimator_\n",
    "gcv.best_params_ , gcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_model(clf,X_balanced, y_balanced, X_original,y_original, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(n_jobs=-1)       \n",
    "\n",
    "parameters = {'C': np.linspace(10,30,50),}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=r_state)\n",
    "\n",
    "gcv = GridSearchCV(logit, parameters, n_jobs=-1, cv=skf, verbose=1,scoring='recall')\n",
    "\n",
    "gcv.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gcv.best_estimator_\n",
    "gcv.best_params_ , gcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_model(clf, X_balanced, y_balanced, X_original,y_original, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросеть\n",
    "\n",
    "Поскольку перед нами не стоит задача распознавания изображений, у нас не так много данных и они не имею слишком большой размерности, то воспользуемся встроенной в SKlearn нейросетью - MultiLayerClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scaler = StandardScaler() \n",
    "scaler.fit_transform(X_train_adasyn)\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(random_state=r_state)\n",
    "parameters = {'activation':['logistic'], 'alpha':[1e-5],'hidden_layer_sizes':[(50,),(60,),(200,)],'learning_rate':['adaptive']}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=r_state)\n",
    "\n",
    "gcv = GridSearchCV(mlp, parameters, n_jobs=-1, cv=skf, verbose=1,scoring='recall')\n",
    "\n",
    "gcv.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gcv.best_estimator_\n",
    "gcv.best_params_ , gcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_model(clf, scaler.transform(X_balanced),y_balanced, scaler.transform(X_original),y_original, scaler.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
