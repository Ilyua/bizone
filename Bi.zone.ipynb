{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import decomposition\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,recall_score,make_scorer\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# стороняя библиотека для работы с несбалансированными датасетами\n",
    "# pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# настройки отображения графиков\n",
    "# %config InlineBackend.figure_format = 'svg' \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "%matplotlib inline\n",
    "\n",
    "# увеличим  размер графиков\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8,7\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# для воспроизводимости\n",
    "r_state = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что все считалось должным образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сперва посмотрим на распределение меток у целевого класса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot(df['Class']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим, насколько мошеннические транзакции коррелируют со временем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df[df['Class']==1]['Time'],100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, распределение числа мошеннических транзакций во времени имеет примерно равномерный характер, следовательно, можно исключить из выборки этот признак. Тем более, что это время отсчитывалось, начиная от первой транзакции, следовательно, оно не имеет ценности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как пространство признаков изображается при двумерной проекции(на примере признаков 'V11', 'V12', 'V13', 'V14', 'V15') :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rcParams['figure.figsize'] = 12,12\n",
    "# sns_plot = sns.pairplot(df,vars=['V11', 'V12', 'V13', 'V14', 'V15'],hue=\"Class\",markers=[\"o\", \"s\"])\n",
    "# rcParams['figure.figsize'] = 8,7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения качественных оценок работы алгоритма, я буду сравнивать такие метрики как:\n",
    "- **Recall score**\n",
    "\n",
    "   Это оценка вида: \n",
    "   \n",
    "   $$score = {tp \\over tp + fn}$$\n",
    "   \n",
    "   tp - число предсказаний, когда модель верно обнаружила нужные транзакции.\n",
    "   \n",
    "   fn - число предсказаний, когда модель не распознала поддельный перевод.\n",
    "   \n",
    "   Чем ближе это значение к 1, тем меньше модель пропускает поддельных транзакций. Но, возможно, она будет помечать некоторые переводы как поддельные, хотя они таковыми не являются. Следующие метрики должны помочь проконтролировать этот аспект.\n",
    "   \n",
    "   \n",
    "- **Accuracy**\n",
    "\n",
    "   Доля верных ответов, будем его тоже учитывать.\n",
    "   \n",
    "   \n",
    "- **ROC AUC score**\n",
    "\n",
    "   Площадь, ограниченная ROC-кривой и осью доли ложных положительных классификаций.\n",
    "   Эта метрика позволяет судить о качестве бинарной классификации и в совокупности с Recall score должна дать нам наглядное представление о работе классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=10000,random_state = r_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью этой функции будем выводить информацию обо всех метриках для данной выборки и классификатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, что получить сбалансированный датасет, я буду использовать алгоритм ADASYN(Adaptive Synthetic Sampling),поскольку SMOTE (Synthetic Minority Over-sampling Technique) создает больше примеров внутри кластера, а ADASYN создает больше синтетических примеров на границе. \n",
    "\n",
    "В случае, когда данные генерируются ADASYN, модель становится более \"подозрительной\", поскольку будет лучше опознавать мошеннические транзакции на границе двух кластеров, ведь ADASYN может расширить границы имеющего кластера. Хотя это и может привести к ошибкам рода False Positive, мне кажется, что такой подход будет надежнее и более подходит для предотвращения мошенничества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производить оценку метрик я буду на трех датасетах.\n",
    "\n",
    "1. На исходном\n",
    "2. На тестовой части датасета.\n",
    "3. На датасете, полученным контатенацией равных долей поддельных транзакций и неподдельных. То есть, я соединил все поддельные транзакции с тем же числом неподдельных. Это нужно, чтобы посмотреть на оценки в случае, когда число поддельных и неподдельных транзакций сбалансированно и данные оригинальные, в таком случае они более точны, поскольку у модели нет возможности предсказывать, допустим только \"0\" и при этом показывать хорошие результаты. (функция ниже)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединим строки поддельных с переводов исходного датасета с таким же количеством неподдельных\n",
    "def create_balanced_data_from_initial(data):\n",
    "    \n",
    "    fraud = data[(data['Class']==1)]\n",
    "    not_fraud = data[(data['Class']==0)]\n",
    "    \n",
    "    n_fraud = len(fraud)//2\n",
    "    \n",
    "\n",
    "    X_original_unb = pd.concat([fraud[n_fraud:].drop(['Class','Time'], axis=1)\n",
    "                                    ,not_fraud[n_fraud:].drop(['Class','Time'], axis=1)])\n",
    "    \n",
    "    y_original_unb = pd.concat([fraud[n_fraud:]['Class']\n",
    "                                    ,not_fraud[n_fraud:]['Class']])\n",
    "    \n",
    "    \n",
    "    X_original_b = pd.concat([fraud[:n_fraud-1].drop(['Class','Time'], axis=1)\n",
    "                                 ,not_fraud[:n_fraud-1].drop(['Class','Time'], axis=1)])\n",
    "    \n",
    "    y_original_b = pd.concat([fraud[:n_fraud-1]['Class']\n",
    "                                 ,not_fraud[:n_fraud-1]['Class']])\n",
    "    \n",
    "\n",
    "    return X_original_unb,y_original_unb,X_original_b,y_original_b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение алгоритма ADASYN\n",
    "def create_balanced_data_adasyn(x,y):\n",
    "    sm = ADASYN(random_state=12, ratio = 'minority')\n",
    "    X,Y = sm.fit_sample(x, y)\n",
    "    X = pd.DataFrame(X,columns = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'] )\n",
    "    Y = pd.DataFrame(Y,columns = ['Class'])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_metrics_validation(clf,X,Y_true):\n",
    "    print(\"Accuracy score: \"+ str(accuracy_score(Y_true,clf.predict(X))))\n",
    "    \n",
    "    print(\"ROC AUC score: \"+ str(roc_auc_score(Y_true,clf.predict_proba(X)[:,1])))\n",
    "    # нас интересуют положительные результаты\n",
    "    print(\"Recall score: \"+ str(recall_score(Y_true,clf.predict(X))))\n",
    "    \n",
    "    print(\"Precicion score: \"+ str(precision_score(Y_true,clf.predict(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка модели на указанных датасетах\n",
    "def estimate_model(clf, X_original_b,y_original_b,  X_test, y_test):\n",
    "\n",
    "    print('\\nМетрики на тестовой части :\\n')\n",
    "    all_metrics_validation(clf,X_test, y_test)\n",
    "    \n",
    "    print('\\nМетрики на небольшой сбалансированой части,составленной из элементов оригинального датасета:\\n')\n",
    "    all_metrics_validation(clf,X_original_b,y_original_b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original_unb,y_original_unb,X_original_b,y_original_b = create_balanced_data_from_initial(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9957\n",
       "1      15\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_original_unb.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13\n",
       "0    13\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_original_b.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим на тестовую и тренировочную\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original_unb,y_original_unb, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, при генерации данных ADASYN, необходимо сначала отделить тестовую и проверочную выборки, а затем для тренировочной сгенерировать новые данные. Тк в противном случае, если сначала создать новых данных, а потом разделить выборку, то синтетические данные попадут в проверочный сет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adasyn, y_train_adasyn = create_balanced_data_adasyn(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot(y_train_adasyn['Class']);y_train_adasyn['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StratifiedKFold - сохраняет процент образцов в тестовом и тренировочных сетах, поэтому такому кросс-валиждатору можно доверять"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 s, sys: 62.8 ms, total: 1.49 s\n",
      "Wall time: 5.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'max_features': ['auto'], 'min_samples_leaf': range(15,20,2),'max_depth': range(3,7,1),'n_estimators':range(10,50,10),'n_jobs':[-1]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=r_state)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "gcv = GridSearchCV(rfc, parameters, n_jobs=-1, cv=skf, verbose=1,scoring='recall')\n",
    "\n",
    "gcv.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 5,\n",
       "  'max_features': 'auto',\n",
       "  'min_samples_leaf': 15,\n",
       "  'n_estimators': 30,\n",
       "  'n_jobs': -1},\n",
       " 0.999856507386915)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = gcv.best_estimator_\n",
    "gcv.best_params_ , gcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Метрики на тестовой части :\n",
      "\n",
      "Accuracy score: 0.9986631016042781\n",
      "ROC AUC score: 0.9993311036789297\n",
      "Recall score: 1.0\n",
      "Precicion score: 0.3333333333333333\n",
      "\n",
      "Метрики на небольшой сбалансированой части,составленной из элементов оригинального датасета:\n",
      "\n",
      "Accuracy score: 0.8461538461538461\n",
      "ROC AUC score: 0.9556213017751479\n",
      "Recall score: 0.6923076923076923\n",
      "Precicion score: 1.0\n"
     ]
    }
   ],
   "source": [
    "estimate_model(clf, X_original_b,y_original_b, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "CPU times: user 164 ms, sys: 58.7 ms, total: 223 ms\n",
      "Wall time: 1.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    0.9s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'n_neighbors': range(10,30,5),'n_jobs':[-1]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=r_state)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "gcv = GridSearchCV(knn, parameters, n_jobs=-1, cv=skf, verbose=1,scoring='recall')\n",
    "\n",
    "gcv.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_jobs': -1, 'n_neighbors': 10}, 1.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = gcv.best_estimator_\n",
    "gcv.best_params_ , gcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Метрики на тестовой части :\n",
      "\n",
      "Accuracy score: 0.9936497326203209\n",
      "ROC AUC score: 0.9993311036789299\n",
      "Recall score: 1.0\n",
      "Precicion score: 0.09523809523809523\n",
      "\n",
      "Метрики на небольшой сбалансированой части,составленной из элементов оригинального датасета:\n",
      "\n",
      "Accuracy score: 0.8076923076923077\n",
      "ROC AUC score: 0.8076923076923077\n",
      "Recall score: 0.6153846153846154\n",
      "Precicion score: 1.0\n"
     ]
    }
   ],
   "source": [
    "estimate_model(clf, X_original_b,y_original_b,  X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    7.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 881 ms, sys: 47.2 ms, total: 928 ms\n",
      "Wall time: 7.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(n_jobs=-1)       \n",
    "\n",
    "parameters = {'C': np.linspace(10,30,50),}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=r_state)\n",
    "\n",
    "gcv = GridSearchCV(logit, parameters, n_jobs=-1, cv=skf, verbose=1,scoring='recall')\n",
    "\n",
    "gcv.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 10.0}, 0.999856507386915)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = gcv.best_estimator_\n",
    "gcv.best_params_ , gcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Метрики на тестовой части :\n",
      "\n",
      "Accuracy score: 0.9979946524064172\n",
      "ROC AUC score: 0.9991638795986623\n",
      "Recall score: 1.0\n",
      "Precicion score: 0.25\n",
      "\n",
      "Метрики на небольшой сбалансированой части,составленной из элементов оригинального датасета:\n",
      "\n",
      "Accuracy score: 0.7307692307692307\n",
      "ROC AUC score: 0.7928994082840237\n",
      "Recall score: 0.46153846153846156\n",
      "Precicion score: 1.0\n"
     ]
    }
   ],
   "source": [
    "estimate_model(clf, X_original_b,y_original_b,  X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросеть\n",
    "\n",
    "Поскольку перед нами не стоит задача распознавания изображений, у нас не так много данных и они не имею слишком большой размерности, то воспользуемся встроенной в SKlearn нейросетью - MultiLayerClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   15.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.7 s, sys: 15 s, total: 22.7 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scaler = StandardScaler() \n",
    "scaler.fit_transform(X_train_adasyn)\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(random_state=r_state)\n",
    "parameters = {'activation':['logistic'], 'alpha':[1e-5],'hidden_layer_sizes':[(50,),(60,),(200,)],'learning_rate':['adaptive']}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=r_state)\n",
    "\n",
    "gcv = GridSearchCV(mlp, parameters, n_jobs=-1, cv=skf, verbose=1,scoring='recall')\n",
    "\n",
    "gcv.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'activation': 'logistic',\n",
       "  'alpha': 1e-05,\n",
       "  'hidden_layer_sizes': (50,),\n",
       "  'learning_rate': 'adaptive'},\n",
       " 1.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = gcv.best_estimator_\n",
    "gcv.best_params_ , gcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Метрики на тестовой части :\n",
      "\n",
      "Accuracy score: 0.9953208556149733\n",
      "ROC AUC score: 0.9979933110367893\n",
      "Recall score: 1.0\n",
      "Precicion score: 0.125\n",
      "\n",
      "Метрики на небольшой сбалансированой части,составленной из элементов оригинального датасета:\n",
      "\n",
      "Accuracy score: 0.7692307692307693\n",
      "ROC AUC score: 0.9822485207100591\n",
      "Recall score: 0.5384615384615384\n",
      "Precicion score: 1.0\n"
     ]
    }
   ],
   "source": [
    "estimate_model(clf, scaler.transform(X_original_b),y_original_b, scaler.transform(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
